{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BetaE Demo\n",
    "Group members: Di Mo, Siyu Zhang "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of BetaE\n",
    "Use beta distribution for query and entity embedding for multi-hop logical reasoning.\n",
    "\n",
    "BetaE can handle all first-order logic queries and can model uncertainty of query.\n",
    "\n",
    "![BetaE approach](BetaE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Description\n",
    "The KG data (FB15k, FB15k-237, NELL995) can be downloaded [here](http://snap.stanford.edu/betae/KG_data.zip). \n",
    "\n",
    "Each folder in the data represents a KG, including the following files.\n",
    "- `train.txt/valid.txt/test.txt`: KG edges\n",
    "- `id2rel/rel2id/ent2id/id2ent.pkl`: KG entity relation dicts\n",
    "- `train-queries/valid-queries/test-queries.pkl`: `defaultdict(set)`, each key represents a query structure, and the value represents the instantiated queries\n",
    "- `train-answers.pkl`: `defaultdict(set)`, each key represents a query, and the value represents the answers obtained in the training graph (edges in `train.txt`)\n",
    "- `valid-easy-answers/test-easy-answers.pkl`: `defaultdict(set)`, each key represents a query, and the value represents the answers obtained in the training graph (edges in `train.txt`) / valid graph (edges in `train.txt`+`valid.txt`)\n",
    "- `valid-hard-answers/test-hard-answers.pkl`: `defaultdict(set)`, each key represents a query, and the value represents the **additional** answers obtained in the validation graph (edges in `train.txt`+`valid.txt`) / test graph (edges in `train.txt`+`valid.txt`+`test.txt`)\n",
    "- `mid2name.tsv`: map freebase mid to entity name. can be downloaded [here](https://drive.google.com/file/d/1RJoOll7p7kLgQoyGKdggehRYY5hyryW3/view?usp=sharing)\n",
    "\n",
    "Note `mid2name` can't find all entity id, this is probably because Freebase is deprecated and we are using an older `mid2name` mapping than the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimental Details\n",
    "\n",
    "##### Hyper Parameters\n",
    "\n",
    "The author provides the finetuned parameters for BetaE and baseline methods(GQE,Q2B)\n",
    "\n",
    "|   |embedding dim|learning rate|batch size|negative sample size|margin|\n",
    "|---|-------------|-------------|----------|--------------------|------|\n",
    "|GQE|800|0.0005|512|128|30|\n",
    "|Q2B|400|0.0005|512|128|30|\n",
    "|BETAE|400|0.0005|512|128|60|\n",
    "\n",
    "In our demo, we are going to run the BetaE model with suggested parameters from the table.\n",
    "\n",
    "Data structure of test_queries (generated with create_queries.py)\n",
    "\n",
    "##### Query structures\n",
    "| Key: query type | structure |\n",
    "| ---- | ----------- |\n",
    "| 1p | ('e', ('r',)) |\n",
    "| 2p | ('e', ('r', 'r')) |\n",
    "| 3p | ('e', ('r', 'r', 'r')) |\n",
    "| 2i | (('e', ('r',)), ('e', ('r',))) |\n",
    "| 3i | (('e', ('r',)), ('e', ('r',)), ('e', ('r',))) |\n",
    "| ip | ((('e', ('r',)), ('e', ('r',))), ('r',)) |\n",
    "| pi | (('e', ('r', 'r')), ('e', ('r',))) |\n",
    "| 2in | (('e', ('r',)), ('e', ('r', 'n'))) |\n",
    "| 3in | (('e', ('r',)), ('e', ('r',)), ('e', ('r', 'n'))) |\n",
    "| inp | ((('e', ('r',)), ('e', ('r', 'n'))), ('r',)) |\n",
    "| pin | (('e', ('r', 'r')), ('e', ('r', 'n'))) |\n",
    "| pni | (('e', ('r', 'r', 'n')), ('e', ('r',))) |\n",
    "| 2u by DNF | (('e', ('r',)), ('e', ('r',)), ('u',)) |\n",
    "| up by DNF | ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',)) |\n",
    "| 2u by DM | ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n',)) |\n",
    "| up by DM | ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n', 'r'))]\n",
    "\n",
    "e:   entities of KGs\n",
    "\n",
    "r:   projection relation, represented by a relation id (positive)\n",
    "\n",
    "n:   negation, represented by the constant -2\n",
    "\n",
    "u:   union, represented by the constant -1\n",
    "\n",
    "DNF: transform queries into disjunctive normal form\n",
    "\n",
    "DM:  transform queries with De Morgan's laws\n",
    "\n",
    "##### Query Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load queries dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use FB15k-237-betae test queries as a example\n",
    "import pickle\n",
    "import os\n",
    "data_path = \"data/FB15k-237-betae\"\n",
    "test_queries = pickle.load(open(os.path.join(data_path, \"test-queries.pkl\"), 'rb'))\n",
    "test_hard_answers = pickle.load(open(os.path.join(data_path, \"test-hard-answers.pkl\"), 'rb'))\n",
    "test_easy_answers = pickle.load(open(os.path.join(data_path, \"test-easy-answers.pkl\"), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((967, (35,)), (8734, (351, -2))),\n",
       " ((3183, (44,)), (592, (49, -2))),\n",
       " ((1002, (35,)), (8638, (152, -2)))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the some queries with structure 2in: (('e', ('r',)), ('e', ('r', 'n')))\n",
    "# -1 is Union, -2 is Negation\n",
    "list(test_queries[(('e', ('r',)), ('e', ('r', 'n')))])[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These queries are not very human readable, so let's define a few helpers to decode them.\n",
    "# Firstly, load necessary dict \n",
    "import csv\n",
    "\n",
    "# Load the id to entity freebase mid dict\n",
    "id2ent = pickle.load(open(os.path.join(data_path, \"id2ent.pkl\"), 'rb'))\n",
    "# Load freebase mid - name mapping\n",
    "import csv\n",
    "mid2name = {}\n",
    "name2mid = {}\n",
    "with open(\"data/mid2name.tsv\") as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    for row in rd:\n",
    "        mid2name[row[0]] = row[1]\n",
    "        name2mid[row[1]] = row[0]\n",
    "\n",
    "\n",
    "# Load the id to relation fict\n",
    "id2rel = pickle.load(open(os.path.join(data_path, \"id2rel.pkl\"), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Decoder function decode query to text\n",
    "def id2name(id:int):\n",
    "    return mid2name[id2ent[id]]\n",
    "def query2text(query_type: tuple, query: tuple, res:str):\n",
    "    n = len(query_type)\n",
    "    res=res+'('\n",
    "    for i in range(n):\n",
    "        if query_type[i] == 'e':\n",
    "            res=res+id2name(query[i])+\",\"\n",
    "        elif query_type[i] == 'r':\n",
    "            res=res+id2rel[query[i]]+\",\"\n",
    "        elif query_type[i] == 'n':\n",
    "            res=res+\"Negation\"\n",
    "        elif query_type[i] == 'u':\n",
    "            res=res+\"Union\"\n",
    "        elif isinstance(query_type[i], tuple):\n",
    "            res = query2text(query_type[i], query[i], res)\n",
    "            if i<n-1:\n",
    "                res+=',\\n'\n",
    "    res = res+')'\n",
    "    # print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Jet Lee,(+/award/award_nominee/award_nominations./award/award_nomination/award,))\n"
     ]
    }
   ],
   "source": [
    "# Given the query type and query to convert the value to string\n",
    "qt = ('e', ('r',))\n",
    "q = (7330, (38,))\n",
    "r = query2text(qt, q,'')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see the answers of this query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hong Kong Film Award for Best Film\n",
      "MTV Movie Award for Best Fight\n",
      "MTV Movie Award for Best Villain\n",
      "Hundred Flowers Award for Best Actor\n"
     ]
    }
   ],
   "source": [
    "for e in test_easy_answers[q]:\n",
    "    print(id2name(e))\n",
    "\n",
    "for e in test_hard_answers[q]:\n",
    "    print(id2name(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Experiment \n",
    "We can use use bash script to run the command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Argument Overview\n",
    "* '--cuda', action='store_true', help='use GPU')\n",
    "    \n",
    "* '--do_train', action='store_true', help=\"do train\")\n",
    "* '--do_valid', action='store_true', help=\"do valid\")\n",
    "* '--do_test', action='store_true', help=\"do test\")\n",
    "\n",
    "* '--data_path', type=str, default=None, help=\"KG data path\")\n",
    "* '-n', '--negative_sample_size', default=128, type=int, help=\"negative entities sampled per query\")\n",
    "* '-d', '--hidden_dim', default=500, type=int, help=\"embedding dimension\")\n",
    "* '-g', '--gamma', default=12.0, type=float, help=\"margin in the loss\")\n",
    "* '-b', '--batch_size', default=1024, type=int, help=\"batch size of queries\")\n",
    "* '--test_batch_size', default=1, type=int, help='valid/test batch size')\n",
    "* '-lr', '--learning_rate', default=0.0001, type=float)\n",
    "* '-cpu', '--cpu_num', default=10, type=int, help=\"used to speed up torch.dataloader\")\n",
    "* '-save', '--save_path', default=None, type=str, help=\"no need to set manually, will configure automatically\")\n",
    "* '--max_steps', default=100000, type=int, help=\"maximum iterations to train\")\n",
    "* '--warm_up_steps', default=None, type=int, help=\"no need to set manually, will configure automatically\")\n",
    "    \n",
    "* '--save_checkpoint_steps', default=50000, type=int, help=\"save checkpoints every xx steps\")\n",
    "* '--valid_steps', default=10000, type=int, help=\"evaluate validation queries every xx steps\")\n",
    "* '--log_steps', default=100, type=int, help='train log every xx steps')\n",
    "* '--test_log_steps', default=1000, type=int, help='valid/test log every xx steps')\n",
    "    \n",
    "* '--nentity', type=int, default=0, help='DO NOT MANUALLY SET')\n",
    "* '--nrelation', type=int, default=0, help='DO NOT MANUALLY SET')\n",
    "    \n",
    "* '--geo', default='vec', type=str, choices=['vec', 'box', 'beta'], help='the reasoning model, vec for GQE, box for Query2box, beta for BetaE')\n",
    "* '--print_on_screen', action='store_true')\n",
    "    \n",
    "* '--tasks', default='1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up', type=str, help=\"tasks connected by dot, refer to the BetaE paper for detailed meaning and structure of each task\")\n",
    "* '--seed', default=0, type=int, help=\"random seed\")\n",
    "* '-betam', '--beta_mode', default=\"(1600,2)\", type=str, help='(hidden_dim,num_layer) for BetaE relational projection')\n",
    "* '-boxm', '--box_mode', default=\"(none,0.02)\", type=str, help='(offset activation,center_reg) for Query2box, center_reg balances the in_box dist and out_box dist')\n",
    "* '--prefix', default=None, type=str, help='prefix of the log path')\n",
    "* '--checkpoint_path', default=None, type=str, help='path for loading the checkpoints')\n",
    "* '-evu', '--evaluate_union', default=\"DNF\", type=str, choices=['DNF', 'DM'], help='the way to evaluate union queries, transform it to disjunctive normal form (DNF) or use the De Morgan\\'s laws (DM)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwritting args.save_path\n",
      "logging to logs/FB15k-237-betae/1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up/beta/g-60.0-mode-(1600,2)/2022.05.31-15:11:11\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 main.py --cuda --do_train --do_valid --do_test \\\n",
    "  --data_path data/FB15k-237-betae -n 128 -b 512 -d 400 -g 60 \\\n",
    "  -lr 0.0005 --max_steps 450001 --cpu_num 1 --geo beta --valid_steps 15000 \\\n",
    "  -betam \"(1600,2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 main.py --cuda --do_test \\\n",
    "  --data_path data/FB15k-237-betae -n 128 -b 512 -d 400 -g 60 \\\n",
    "  -lr 0.0005 --max_steps 450001 --cpu_num 1 --geo beta --valid_steps 15000 \\\n",
    "  -betam \"(1600,2)\" --checkpoint_path /home_ssd2/dimo/BetaE/logs/FB15k-237-betae/1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up/beta/g-60.0-mode-\\(1600,2\\)/2022.05.16-16:08:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize Results\n",
    "Use tensorboard to visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 80877), started 1 day, 1:33:04 ago. (Use '!kill 80877' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6858861ecc735956\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6858861ecc735956\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n",
    "# reload_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on dataset FB15k-237, Union operation by DNF\n",
    "GPU: GeForce RTX 2080 Ti Rev. A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    |1p   |2p   |3p   |2i   |3i.  |ip.  |pi.  |2in. |3in. |inp. |pin. |pni  |2u.  |up.  |avg. |\n",
    "|----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "|MRR |33.74|8.39 | 8.04|21.08|33.64| 8.66|16.40| 4.61| 5.85| 6.37| 3.17| 3.16| 9.42| 7.31|12.13|\n",
    "|H@1 |24.14|3.62 | 3.65|11.74|23.07| 3.92| 9.16| 1.52| 1.67| 2.34| 0.64| 0.86| 4.55| 2.82| 6.69|\n",
    "|H@3 |37.10|8.23 | 7.90|23.03|37.41| 8.69|17.31| 3.64| 5.10| 5.66| 2.37| 2.20| 9.17| 7.03|12.49|\n",
    "|H@10|53.42|17.40|16.41|40.90|55.89|17.54|31.15| 9.70|13.15|13.97| 7.18| 6.64|18.64|15.85|22.70|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The paper's results on dataset FB15k-237 Union operation by DNF\n",
    "|    |1p   |2p   |3p   |2i   |3i.  |ip.  |pi.  |2in. |3in. |inp. |pin. |pni  |2u.  |up.  |avg. |\n",
    "|----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "|MRR | 39.0| 10.9| 10.0| 28.8| 42.5|12.6 | 22.4|5.1  | 7.9 | 7.4 | 3.6 | 3.4 | 12.4| 9.7 |     |\n",
    "|H@1 |28.9 |5.5  | 4.9 | 18.3 |31.7| 6.7 | 14.0|     |     |     |     |     |  6.3|  4.6|     |\n",
    "|H@10|     |     |     |     |     |     |     | 11.3|17.3 |16.0 | 8.1 | 7.0 |     |     |     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models import KGReasoning\n",
    "from dataloader import TestDataset, TrainDataset, SingledirectionalOneShotIterator\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from util import flatten_query, list2tuple, parse_time, set_global_seed, eval_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KGReasoning(\n",
       "  (center_net): BetaIntersection(\n",
       "    (layer1): Linear(in_features=800, out_features=800, bias=True)\n",
       "    (layer2): Linear(in_features=800, out_features=400, bias=True)\n",
       "  )\n",
       "  (projection_net): BetaProjection(\n",
       "    (layer1): Linear(in_features=1200, out_features=1600, bias=True)\n",
       "    (layer0): Linear(in_features=1600, out_features=800, bias=True)\n",
       "    (layer2): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "from main import query_name_dict\n",
    "N_ENTITY = 14505\n",
    "N_RELATION = 474\n",
    "\n",
    "model = KGReasoning(nentity=N_ENTITY, nrelation=N_RELATION, hidden_dim=400, gamma=60, \n",
    "                    geo='beta', beta_mode=(1600,2), query_name_dict=query_name_dict)\n",
    "# NOTE: nentity=14505, nrelation=474 must match dataset stats\n",
    "checkpoint_path = \"logs/FB15k-237-betae/1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up/beta/g-60.0-mode-(1600,2)/2022.06.05-16:49:08\"\n",
    "checkpoint = torch.load(os.path.join(checkpoint_path, 'checkpoint'))\n",
    "init_step = checkpoint['step']\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_query(qt, q):\n",
    "    print(\"==========Query is\")\n",
    "    print(query2text(query_type=qt,query=q,res=\"\"))\n",
    "    # prepare data\n",
    "    infer_data = defaultdict(set)\n",
    "    infer_data[qt] = {q}\n",
    "    infer_queries = flatten_query(infer_data)\n",
    "    infer_dataloader = DataLoader(\n",
    "        TestDataset(\n",
    "            infer_queries, \n",
    "            N_ENTITY, \n",
    "            N_RELATION, \n",
    "        ), \n",
    "        batch_size=1,\n",
    "        num_workers=1, \n",
    "        collate_fn=TestDataset.collate_fn\n",
    "    )\n",
    "\n",
    "\n",
    "    # Use the model to find results\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for negative_sample, queries, queries_unflatten, query_structures in infer_dataloader:\n",
    "            batch_queries_dict = defaultdict(list)\n",
    "            batch_idxs_dict = defaultdict(list)\n",
    "            for i, query in enumerate(queries):\n",
    "                batch_queries_dict[query_structures[i]].append(query)\n",
    "                batch_idxs_dict[query_structures[i]].append(i)\n",
    "            for query_structure in batch_queries_dict:\n",
    "                batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure]).cuda()\n",
    "            negative_sample = negative_sample.cuda()\n",
    "\n",
    "            _, negative_logit, _, idxs = model(None, negative_sample, None, batch_queries_dict, batch_idxs_dict)\n",
    "            queries_unflatten = [queries_unflatten[i] for i in idxs]\n",
    "            query_structures = [query_structures[i] for i in idxs]\n",
    "            argsort = torch.argsort(negative_logit, dim=1, descending=True) # the results entities \n",
    "            ranking = argsort.clone().to(torch.float)\n",
    "            ranking = ranking.scatter_(1, argsort, model.batch_entity_range.cuda()) # achieve the ranking of all entities\n",
    "    # The answers get through trained model\n",
    "    print(\"\\n==========Answers get through trained model Top10\")\n",
    "    for i in range(10):\n",
    "        res_id = int(argsort.cpu()[0][i])\n",
    "        print(id2name(res_id))\n",
    "    print(\"\\n==========Test answers\")\n",
    "    hard_answer = test_hard_answers[q]\n",
    "    easy_answer = test_easy_answers[q]\n",
    "    easy_i = 0\n",
    "    for ans_id in easy_answer:\n",
    "        if easy_i>10:\n",
    "            break\n",
    "        try:\n",
    "            print(id2name(ans_id))\n",
    "            easy_i+=1\n",
    "        except e:\n",
    "            pass\n",
    "    hard_i=0\n",
    "    for ans_id in hard_answer:\n",
    "        if hard_i>10:\n",
    "            break\n",
    "        try:\n",
    "            print(id2name(ans_id))\n",
    "            hard_i+=1\n",
    "        except e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Query is\n",
      "(Jet Lee,(+/award/award_nominee/award_nominations./award/award_nomination/award,))\n",
      "\n",
      "==========Answers get through trained model Top10\n",
      "MTV Movie Award for Best Fight\n",
      "Razzie Award for Worst Supporting Actor\n",
      "Hong Kong Film Award for Best Film\n",
      "Hundred Flowers Award for Best Actor\n",
      "Writers Guild of America Award for Best Original Screenplay\n",
      "MTV Movie Award for Best Villain\n",
      "Palme d’Or\n",
      "Hong Kong Film Awards for Best Action Choreography\n",
      "MTV Movie Award for Best Kiss\n",
      "Bafta award for best original screenplay\n",
      "\n",
      "==========Test answers\n",
      "Hong Kong Film Award for Best Film\n",
      "MTV Movie Award for Best Fight\n",
      "MTV Movie Award for Best Villain\n",
      "Hundred Flowers Award for Best Actor\n"
     ]
    }
   ],
   "source": [
    "#Example query 1: Awards won and nominated for by Jet Lee \n",
    "qt = ('e', ('r',))\n",
    "q = (7330, (38,))\n",
    "inference_query(qt=qt,q=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Query is\n",
      "(The Taito Corporation,(-/organization/organization/child./organization/organization_relationship/child,))\n",
      "\n",
      "==========Answers get through trained model Top10\n",
      "Koei Tecmo Holdings Co., Ltd.\n",
      "JOCX\n",
      "NAMCO BANDAI Mirai-Kenkyusho\n",
      "Presidency College, Kolkata\n",
      "Bharatiya Janta Party\n",
      "Sony Computer Entertainment Asia\n",
      "Oregroun\n",
      "UK Royal Navy\n",
      "Microsoft Inc\n",
      "G. Washington University\n",
      "\n",
      "==========Test answers\n",
      "Sukueia Enikkusu\n"
     ]
    }
   ],
   "source": [
    "# Example query2: find child organization of The Taito Corporation\n",
    "qt = ('e', ('r',))\n",
    "q= (13632, (415,))\n",
    "inference_query(qt=qt,q=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Query is\n",
      "(((The Grammy Awards,(-/time/event/instance_of_recurring_event,)),\n",
      "(Thomas, Rob,(-/award/award_ceremony/awards_presented./award/award_honor/award_winner,)),\n",
      "(Union)),\n",
      "(+/award/award_ceremony/awards_presented./award/award_honor/award_winner,))\n",
      "\n",
      "==========Answers get through trained model Top10\n",
      "3 Quid\n",
      "T Bone Burnett\n",
      "List of people likened to Bob Dylan\n",
      "V.S.O.P. (group)\n",
      "Springsteen\n",
      "Allison Krausse\n",
      "LVs & Autotune\n",
      "Slim shady\n",
      "Alicia Cook\n",
      "Sheryl Suzanne Crow\n",
      "\n",
      "==========Test answers\n",
      "Sheryl Suzanne Crow\n",
      "Rod Steward\n",
      "The temptations\n",
      "Haggard, Merle\n",
      "New Age (Kylie Minogue album)\n",
      "Radio head\n",
      "List of awards and nominations received by Korn\n",
      "Clint Black\n",
      "Lorca Cohen\n",
      "Christopher Haden-Guest, 5th Baron Haden-Guest\n",
      "Manny Maroquinn\n",
      "Chase Chad\n",
      "Whitney houston\n",
      "Graham Greene (actor)\n",
      "Trevor horn\n",
      "Coalbear\n",
      "Fifty cent\n",
      "Smashing Pumpkins (band)\n",
      "Gyorgy Stern\n",
      "Karen Astley\n",
      "The Bruce Hornsby Trio\n",
      "Teddy Landau\n"
     ]
    }
   ],
   "source": [
    "qt = ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',))\n",
    "# q = random.choice(tuple(test_queries[qt]))\n",
    "q = (((2192, (421,)), (6102, (55,)), (-1,)), (54,))\n",
    "inference_query(qt=qt,q=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Query is\n",
      "((Comedy performer,(-/people/person/profession,)),\n",
      "(Shemp howard,(-/people/person/sibling_s./people/sibling_relationship/sibling,Negation)))\n",
      "\n",
      "==========Answers get through trained model Top10\n",
      "Tina Faye\n",
      "Frissbeetarianism\n",
      "Elizabeth Ann Powel\n",
      "Will Arnet\n",
      "Carey Fisher\n",
      "Amy Pohler\n",
      "Hank azaria\n",
      "Give the Jew Girl Toys\n",
      "Jason sudeikas\n",
      "Kirsten Wigg\n",
      "\n",
      "==========Test answers\n",
      "Deborah messing\n",
      "Roberto Benini\n",
      "Laura Deibel\n",
      "Mel Blank\n",
      "Merv the Perv\n",
      "Seth Rogan\n",
      "Paula Sutor\n",
      "Marxist of the groucho variety\n",
      "Louie De Palma\n",
      "Bernice Frankel\n",
      "Lori Wolf\n",
      "John Ritter\n",
      "Christopher Graham Collins\n",
      "MC Gainey\n",
      "Clams on the Half-Shell Revue\n",
      "Michael Rappaport\n",
      "Thomas Lennon (actor and screenwriter)\n",
      "Reiser Paul\n",
      "Anna Kay Faris\n",
      "Johny Lever\n",
      "Maurice Lamarche\n",
      "No one will ever believe you\n"
     ]
    }
   ],
   "source": [
    "qt= (('e', ('r',)), ('e', ('r', 'n')))\n",
    "q=((967, (35,)), (8734, (351, -2)))\n",
    "inference_query(qt=qt,q=q)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
